{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting hotspots of burglaries\n",
    "\n",
    "In this tutorial, hotspots of burglaries will be predicted in the city of Dallas. Three different models will be trained and their predictions will be validated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by importing the hotspot library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-05T03:53:27.212785Z",
     "iopub.status.busy": "2020-08-05T03:53:27.212503Z",
     "iopub.status.idle": "2020-08-05T03:53:29.156023Z",
     "shell.execute_reply": "2020-08-05T03:53:29.155288Z",
     "shell.execute_reply.started": "2020-08-05T03:53:27.212756Z"
    }
   },
   "outputs": [],
   "source": [
    "import predictivehp.processing.data_processing as dp\n",
    "import predictivehp.models.models as models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing crime data\n",
    "\n",
    "The tutorial will consider crime data provided by the City of Dallas. The data can be imported with the Socrata API. The street map and city limits can be obtained from Dallas City Hall (https://gis.dallascityhall.com/shapefileDownload.aspx). For convenience, the data has already been stored in the package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-07-29T17:31:50.155921Z",
     "iopub.status.busy": "2020-07-29T17:31:50.155697Z",
     "iopub.status.idle": "2020-07-29T17:31:50.159147Z",
     "shell.execute_reply": "2020-07-29T17:31:50.158014Z",
     "shell.execute_reply.started": "2020-07-29T17:31:50.155895Z"
    }
   },
   "outputs": [],
   "source": [
    "#Â CONSULTAR\n",
    "\n",
    "# data = hp.import.tutorial('Dallas2017')\n",
    "# The 'data' output is an instance of an object, which has all the relevant\n",
    "# information and data such as a dataframe with incidences and shape files of\n",
    "# the city. Either store the data in a folder or request data from Socrata with\n",
    "# default parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, data can be retrieved from the Socrata API and shape files can be specified as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-05T03:53:32.291254Z",
     "iopub.status.busy": "2020-08-05T03:53:32.290993Z",
     "iopub.status.idle": "2020-08-05T03:53:49.425995Z",
     "shell.execute_reply": "2020-08-05T03:53:49.425033Z",
     "shell.execute_reply.started": "2020-08-05T03:53:32.291227Z"
    }
   },
   "outputs": [],
   "source": [
    "b_path = 'predictivehp/data'\n",
    "s_shp_p = f'{b_path}/streets.shp'\n",
    "c_shp_p = f'{b_path}/councils.shp'\n",
    "cl_shp_p = f'{b_path}/citylimit.shp'\n",
    "\n",
    "pp = dp.PreProcessing()\n",
    "shps = pp.shps_processing(s_shp_p, c_shp_p, cl_shp_p)\n",
    "data = pp.get_data(year=2017, n=150000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The crime data is stored in a Pandas DataFrame where columns **x** and **y** are the location coordinates in meters and **date** the date of the crime event."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-05T03:54:01.274226Z",
     "iopub.status.busy": "2020-08-05T03:54:01.273928Z",
     "iopub.status.idle": "2020-08-05T03:54:01.288344Z",
     "shell.execute_reply": "2020-08-05T03:54:01.287530Z",
     "shell.execute_reply.started": "2020-08-05T03:54:01.274194Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>date</th>\n",
       "      <th>month1</th>\n",
       "      <th>y_day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.526789e+06</td>\n",
       "      <td>6.972383e+06</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>January</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.525848e+06</td>\n",
       "      <td>6.971430e+06</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>January</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.483264e+06</td>\n",
       "      <td>6.927857e+06</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>January</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.504030e+06</td>\n",
       "      <td>6.966014e+06</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>January</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.479656e+06</td>\n",
       "      <td>6.956554e+06</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>January</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              x             y        date   month1  y_day\n",
       "0  2.526789e+06  6.972383e+06  2017-01-01  January      1\n",
       "1  2.525848e+06  6.971430e+06  2017-01-01  January      1\n",
       "2  2.483264e+06  6.927857e+06  2017-01-01  January      1\n",
       "3  2.504030e+06  6.966014e+06  2017-01-01  January      1\n",
       "4  2.479656e+06  6.956554e+06  2017-01-01  January      1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify the prediction configuration\n",
    "\n",
    "Data has been loaded for the entire year of 2017. In this tutorial, the first week of November will be predicted from previous crime data. Since data is available for this week, the prediction can be validated as well.\n",
    "\n",
    "All three available models, that is, STKDE, ProMap and Random Forest will be used for the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-05T03:59:18.156323Z",
     "iopub.status.busy": "2020-08-05T03:59:18.155946Z",
     "iopub.status.idle": "2020-08-05T03:59:22.910196Z",
     "shell.execute_reply": "2020-08-05T03:59:22.909013Z",
     "shell.execute_reply.started": "2020-08-05T03:59:18.156290Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "\t\t Promap\n",
      "\thx: 100 mts, hy: 100 mts\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'ProMap' object has no attribute 'bw_x'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-032e2e7b4dc9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdatetime\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m model = models.create_model(data=data,\n\u001b[0m\u001b[1;32m      3\u001b[0m                             \u001b[0mshps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                             \u001b[0mstart_prediction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2017\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m11\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                             \u001b[0mlength_prediction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/iPres/iPre 1/predictivehp/models/models.py\u001b[0m in \u001b[0;36mcreate_model\u001b[0;34m(data, shps, start_prediction, length_prediction, use_stkde, use_promap, use_rfr)\u001b[0m\n\u001b[1;32m   2261\u001b[0m         \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpromap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mProMap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_prediction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstart_prediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2262\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0muse_rfr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2263\u001b[0;31m         m.rfr = RForestRegressor(\n\u001b[0m\u001b[1;32m   2264\u001b[0m             \u001b[0mi_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2265\u001b[0m             \u001b[0mstart_prediction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstart_prediction\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtimedelta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdays\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/iPres/iPre 1/predictivehp/models/models.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, n_datos, read_density, hx, hy, radio, ventana_dias, tiempo_entrenamiento, start_prediction, km2, name, shps)\u001b[0m\n\u001b[1;32m   1919\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_grid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1920\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1921\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mread_density\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1922\u001b[0m             self.score = np.load(\n\u001b[1;32m   1923\u001b[0m                 'predictivehp/data/prediction.npy')\n",
      "\u001b[0;32m~/Documents/iPres/iPre 1/predictivehp/models/models.py\u001b[0m in \u001b[0;36mcreate_grid\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1947\u001b[0m         print(f'\\tbw.x: {self.bw_x} mts, bw.y: {self.bw_y} '\n\u001b[1;32m   1948\u001b[0m               f'mts, bw.t: {self.bw_t} dias')\n\u001b[0;32m-> 1949\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1950\u001b[0m         \u001b[0mdelta_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhx\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1951\u001b[0m         \u001b[0mdelta_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhy\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ProMap' object has no attribute 'bw_x'"
     ]
    }
   ],
   "source": [
    "from datetime import date\n",
    "model = models.create_model(data=data,\n",
    "                            shps=shps,\n",
    "                            start_prediction=date(2017, 11, 1),\n",
    "                            length_prediction=7,\n",
    "                            use_stkde=False,\n",
    "                            use_promap=True,\n",
    "                            use_rfr=False)\n",
    "# The output is an object that has all relevant attributes, for example the data\n",
    "# for the incidences and a separate object for each model (stkde, promap, rfr)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specifying model parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optionally, hyperparameters for the predictive models can be specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-05T01:50:44.351562Z",
     "iopub.status.busy": "2020-08-05T01:50:44.351292Z",
     "iopub.status.idle": "2020-08-05T01:50:44.355027Z",
     "shell.execute_reply": "2020-08-05T01:50:44.354131Z",
     "shell.execute_reply.started": "2020-08-05T01:50:44.351534Z"
    }
   },
   "outputs": [],
   "source": [
    "model.stkde.set_parameters(bw=[100, 200, 20])\n",
    "# No output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.promap.set_parameters(bandwidth=[400, 400, 7],\n",
    "                            hx=100, hy=100)\n",
    "# No output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-05T01:52:35.165766Z",
     "iopub.status.busy": "2020-08-05T01:52:35.165386Z",
     "iopub.status.idle": "2020-08-05T01:52:35.170419Z",
     "shell.execute_reply": "2020-08-05T01:52:35.169377Z",
     "shell.execute_reply.started": "2020-08-05T01:52:35.165721Z"
    }
   },
   "outputs": [],
   "source": [
    "model.rfr.set_parameters(t_history=4,\n",
    "                         xc_size=100, yc_size=100, n_layers=7,\n",
    "                         label_weights=None)\n",
    "# No output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.print_parameters()\n",
    "# Print all hyperparameters of the models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the models\n",
    "\n",
    "The models will be trained on historical crime data to optimize the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit()\n",
    "# No output other than messages. Perform the calculations for the training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The STKDE model has calculated the optimal space-time bandwidth for the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.stkde.bw\n",
    "# Output is a list of the x-, y-, and t-bandwidth."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ProMap model is a *lazy learner* and does not require any training: the space-time weights are fixed and only a rectangular mesh needs to be created."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The RFR model has created a forest of decision trees. Interestingly, the relative importance of the features can be retrieved. The table shows the feature importance with respect to the units of history and the depth of the layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.rfr.plot_feature_importance()\n",
    "# Output is a table with the index of the layer and the index of the histor\n",
    "# unit (for example, week -1, week -2, until week -n). Color and values indicate\n",
    "# the feature importance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting future crimes\n",
    "\n",
    "The crimes in the first week of November will be predicted with the different models. The results are risk scores that indicate the likelihood of a future crime to occur at the specific location. These propensity scores are normalized to a scale of 0 to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict()\n",
    "# No output other than messages. Perform the calculations for the prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The STKDE has created a function stating the risk associated to an arbitrary point on the map for any time in the prediction window. This score can be calculated at each point in space and time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.stkde.score(x=123456, y=987654, t=4)\n",
    "# Output is the value of the 'pdf' function in this point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ProMap model has created propensity scores for each cell in the rectangular mesh. These are stored in a matrix where each element corresponds to the score of the corresponding cell in the mesh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.promap.score()\n",
    "# Output is the matrix with scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, RFR also creates scores for each cell in a rectangular mesh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.rfr.score()\n",
    "# Output is the column of the dataframe with the predicted values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the prediction\n",
    "\n",
    "The prediction can be vizualized as a heat map, where the values indicate the likelihood of crime occurrence in the prediction window. Normally, hotspots of areas with a high crime risk can be seen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.plot_heatmap()\n",
    "# Plot the heatmaps of all models, with the same axis and the same colorbar.\n",
    "# Include optional parameters like 'crange=[0.2,0.8]' to plot values between 0.2\n",
    "# and 0.8 only, cmap='jet', xlim=[123456,234567], savefig=True, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The STKDE method provides space-time prediction, which can be visualized with a four-dimensional plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.stkde.plot_4Dheatmap()\n",
    "# Output is the 4D heatmap. If not inline, store the data in a file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation of the prediction\n",
    "\n",
    "When data is available for the prediction window, the predictions can be validated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The testing procedures consists of an experiment where we assume that all areas with a high score will be patrolled and all incidences of crimes in this hotspot area will be detected. Multiple thresholds of the propensity score can be specified at the same time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.validate(score=[0.5, 0.9])\n",
    "# No output other than messages. Perform calculations of the propensity score\n",
    "# for these values of c."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The models have calculated the number of detected incidences for each score threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.detected_incidences()\n",
    "# The output is the number of hits for each model and each value of c."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More detected incidences indicates a better performance of the model. However, this could be at the expense of a larger area to be patrolled. Hence, it is important to calculate the area of the hotspots as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.hotspot_area()\n",
    "# The output is the hotspot area for each model and each value of c."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hit rate\n",
    "\n",
    "Different models can perform better for a smaller or larger area of the hotspots. Therefore, let us plot the hit rate with respect to the area. The *hit rate* is defined by the number of detected incidences inside the hotspot, divided by the total number of crime incidences in the prediction window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.plot_hr()\n",
    "# The output is a figure with the HR for each model.\n",
    "# Optional parameters can be colors=['r','b','g'], models=['stkde','promap'],\n",
    "# title='mytitle', savefig=True, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictive accuracy index\n",
    "\n",
    "The hit rate will always increase for larger hotspot areas. To balance the merits of many hits and the costs of a large area, the predictive accuracy index (PAI) can be used. It is defined as the hit rate divided by the percentage of the hotspot area compared to the city size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.plot_pai()\n",
    "# The output is a figure with the PAI for each model.\n",
    "# Optional parameters as in plot_hr()."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heatmap\n",
    "\n",
    "The performance can also be visualized by a heatmap. For a given score threshold, the hotspots are marked by the blue areas. The markers represent the incidences in the prediction window where green marker are hits and red markers misses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.plot_heatmap(c=0.5, incidences=True)\n",
    "# Plot heatmaps for each model. In this case with red (or another color) for\n",
    "# areas with c larger than the input.\n",
    "# The rest of the area is transparent. Also, plot the incidences in the\n",
    "# prediction window with markers (points, crosses, etc.) with different colors\n",
    "# for the hits and misses.\n",
    "# In general, you want to specify the area, not the c. For example,\n",
    "# when area=0.05, you want to plot the hotspots with 5% of the total area. So,\n",
    "# you need to retrieve the corresponding c for each model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storing data\n",
    "\n",
    "The data of the models can be stored, which is convenient to reduce computational time when performing the same simulation another time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.store(file_name='model.data')\n",
    "# Store all usefull data to disk. Can be NumPy arrays or Pickle objects and in\n",
    "# different files."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iPre_venv",
   "language": "python",
   "name": "ipre_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
